{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv(\"tips.csv\")\n\ndf.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 72,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   total_bill   tip     sex smoker  day    time  size  price_per_person  \\\n0       16.99  1.01  Female     No  Sun  Dinner     2              8.49   \n1       10.34  1.66    Male     No  Sun  Dinner     3              3.45   \n2       21.01  3.50    Male     No  Sun  Dinner     3              7.00   \n3       23.68  3.31    Male     No  Sun  Dinner     2             11.84   \n4       24.59  3.61  Female     No  Sun  Dinner     4              6.15   \n\n           Payer Name         CC Number Payment ID  \n0  Christy Cunningham  3560325168603410    Sun2959  \n1      Douglas Tucker  4478071379779230    Sun4608  \n2      Travis Walters  6011812112971322    Sun4458  \n3    Nathaniel Harris  4676137647685994    Sun5260  \n4        Tonya Carter  4832732618637221    Sun2251  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>sex</th>\n      <th>smoker</th>\n      <th>day</th>\n      <th>time</th>\n      <th>size</th>\n      <th>price_per_person</th>\n      <th>Payer Name</th>\n      <th>CC Number</th>\n      <th>Payment ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16.99</td>\n      <td>1.01</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n      <td>8.49</td>\n      <td>Christy Cunningham</td>\n      <td>3560325168603410</td>\n      <td>Sun2959</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.34</td>\n      <td>1.66</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>3.45</td>\n      <td>Douglas Tucker</td>\n      <td>4478071379779230</td>\n      <td>Sun4608</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.01</td>\n      <td>3.50</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n      <td>7.00</td>\n      <td>Travis Walters</td>\n      <td>6011812112971322</td>\n      <td>Sun4458</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.68</td>\n      <td>3.31</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n      <td>11.84</td>\n      <td>Nathaniel Harris</td>\n      <td>4676137647685994</td>\n      <td>Sun5260</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.59</td>\n      <td>3.61</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>4</td>\n      <td>6.15</td>\n      <td>Tonya Carter</td>\n      <td>4832732618637221</td>\n      <td>Sun2251</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 72
    },
    {
      "cell_type": "markdown",
      "source": "### What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application\n\nMin-Max scaling, also known as normalization, is a data preprocessing technique used to scale the features of your data to a fixed range, typically [0, 1]. This is particularly useful when you want to ensure that all features contribute equally to the model, especially when they have different units or scales.\n\n**Why Use Min-Max Scaling?**\nUniform Contribution: Ensures that all features contribute equally to the model.\nAlgorithm Sensitivity: Some algorithms, like K-Nearest Neighbors (KNN) and Neural Networks, are sensitive to the scale of the data.\nPreserves Relationships: Maintains the relationships between the data points.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## Eg : \n\nfrom sklearn.preprocessing import MinMaxScaler\nmin_max_scaler=MinMaxScaler()\nmin_max_scaler.fit_transform(df[['total_bill' , 'tip']])\n\nmin_max_scaler.transform([[23, 9]])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 73,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.41746963, 0.88888889]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73
    },
    {
      "cell_type": "markdown",
      "source": "### What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application\n\n\nThe Unit Vector technique, also known as normalization, scales each data point (row) to have a unit norm (length of 1). This is different from Min-Max scaling, which scales features to a fixed range, typically [0, 1].\n\n**Unit Vector Scaling (Normalization):**\n\nFunction: Scales each data point to have a unit norm.\nUse Case: Useful when you want to ensure that each data point has the same length, often used in clustering algorithms like K-Means and in text classification.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nfrom sklearn.preprocessing import Normalizer\n\nunit_vector=Normalizer()\nunit_vector.fit_transform(df[['total_bill']])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 74,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.],\n       [1.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 74
    },
    {
      "cell_type": "markdown",
      "source": "### What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an  example to illustrate its application\n\n\n**Principal Component Analysis (PCA)** is a statistical technique used for dimensionality reduction. It transforms the data into a new coordinate system where the greatest variances by any projection of the data come to lie on the first coordinates (called principal components), the second greatest variances on the second coordinates, and so on.\n\n\n**Why Use PCA?**\nDimensionality Reduction: Reduces the number of features while retaining the most important information.\nVisualization: Helps in visualizing high-dimensional data in 2D or 3D.\nNoise Reduction: Removes noise and redundancy in the data.\nImproves Performance: Can improve the performance of machine learning algorithms by reducing overfitting.\n\n**Principal Components are New Axes:**\n\nPrincipal components are new directions in the feature space. They are not the same as the original features but are derived from them.\nEach principal component is a linear combination of the original features.\n\n**Maximizing Variance:**\n\nThe first principal component (PC1) is the direction that captures the maximum variance in the data. It is the direction along which the data points are most spread out.\nThe second principal component (PC2) is orthogonal to PC1 and captures the next highest variance.\n\n### What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept\n\n**Relationship Between PCA and Feature Extraction**\nPrincipal Component Analysis (PCA) is a powerful technique used for feature extraction. Feature extraction involves creating new features from the existing ones, and PCA does this by transforming the original features into a new set of features called principal components. These principal components capture the most important information (variance) in the data, effectively reducing its dimensionality.\n\n**How PCA is Used for Feature Extraction**\n\n1. Identify Principal Components: PCA identifies the directions (principal components) in which the data varies the most.\n2. Transform Data: The original data is transformed into a new coordinate system defined by these principal components.\n3. Reduce Dimensionality: By selecting the top principal components, you can reduce the number of features while retaining the most important information",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### You are working on a project to build a recommendation system for a food delivery service. The dataset  contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to  preprocess the data.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nfeatures=['price' , 'rating' , 'delivery time' ]\n\nprice=np.random.randint(1 , 500 , 100)\nrating =np.random.uniform(1 , 5 ,100)\nrating=np.round(rating , 1)\ntime=np.random.randint(25 ,40 , 100)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": "df1=pd.DataFrame(price , columns=['Price'])\ndf2=pd.DataFrame(rating ,  columns=['rating'])\ndf3=pd.DataFrame(time , columns=['delivery time'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": "final_df=pd.concat((df1 , df2 , df3) , axis=1)\nfinal_df",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 81,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    Price  rating  delivery time\n0     143     4.3             36\n1     296     4.0             30\n2     479     2.0             34\n3     378     3.7             29\n4     234     1.4             33\n..    ...     ...            ...\n95    195     3.5             31\n96    453     1.7             31\n97    416     2.4             28\n98    489     4.1             25\n99    322     1.5             28\n\n[100 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>rating</th>\n      <th>delivery time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>143</td>\n      <td>4.3</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>296</td>\n      <td>4.0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>479</td>\n      <td>2.0</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>378</td>\n      <td>3.7</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>234</td>\n      <td>1.4</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>195</td>\n      <td>3.5</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>453</td>\n      <td>1.7</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>416</td>\n      <td>2.4</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>489</td>\n      <td>4.1</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>322</td>\n      <td>1.5</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\n\nscaler=MinMaxScaler()\nscaler.fit_transform(final_df[['Price' , 'rating' , 'delivery time']])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 83,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.26899384, 0.825     , 0.78571429],\n       [0.58316222, 0.75      , 0.35714286],\n       [0.95893224, 0.25      , 0.64285714],\n       [0.75154004, 0.675     , 0.28571429],\n       [0.45585216, 0.1       , 0.57142857],\n       [0.34907598, 0.775     , 0.92857143],\n       [0.29568789, 0.85      , 0.85714286],\n       [0.22587269, 0.75      , 0.        ],\n       [0.77207392, 0.8       , 0.71428571],\n       [0.74332649, 0.125     , 0.85714286],\n       [0.63039014, 0.2       , 0.07142857],\n       [0.56673511, 0.1       , 0.42857143],\n       [0.28336756, 0.925     , 0.07142857],\n       [0.93839836, 0.95      , 0.21428571],\n       [0.54620123, 0.375     , 1.        ],\n       [0.30184805, 0.9       , 0.42857143],\n       [0.26488706, 0.85      , 0.21428571],\n       [0.33470226, 0.875     , 0.78571429],\n       [0.91991786, 0.15      , 0.85714286],\n       [0.60574949, 0.25      , 0.21428571],\n       [0.98767967, 0.05      , 0.57142857],\n       [0.83778234, 0.075     , 0.42857143],\n       [0.02053388, 0.225     , 0.07142857],\n       [0.48049281, 0.575     , 0.85714286],\n       [1.        , 0.775     , 0.28571429],\n       [0.85831622, 0.375     , 0.        ],\n       [0.6201232 , 0.6       , 0.35714286],\n       [0.02053388, 0.4       , 0.28571429],\n       [0.26283368, 0.85      , 0.14285714],\n       [0.73921971, 0.25      , 0.92857143],\n       [0.50924025, 0.625     , 0.14285714],\n       [0.82546201, 1.        , 0.64285714],\n       [0.94455852, 0.        , 0.64285714],\n       [0.77412731, 0.35      , 0.14285714],\n       [0.15811088, 0.825     , 1.        ],\n       [0.97330595, 0.75      , 0.57142857],\n       [0.41067762, 0.925     , 0.57142857],\n       [0.85831622, 0.125     , 0.71428571],\n       [0.47227926, 0.575     , 0.64285714],\n       [0.96919918, 0.675     , 0.35714286],\n       [0.11293634, 0.075     , 0.92857143],\n       [0.55852156, 0.525     , 0.28571429],\n       [0.19507187, 0.825     , 0.57142857],\n       [0.05338809, 0.725     , 0.64285714],\n       [0.81724846, 0.925     , 0.21428571],\n       [0.55441478, 0.775     , 0.        ],\n       [0.81724846, 0.275     , 0.28571429],\n       [0.65297741, 0.75      , 0.        ],\n       [0.32648871, 0.525     , 0.14285714],\n       [0.19712526, 0.975     , 0.        ],\n       [0.53182752, 0.95      , 0.64285714],\n       [0.89322382, 0.5       , 0.35714286],\n       [0.82340862, 0.425     , 0.5       ],\n       [0.36960986, 0.525     , 0.92857143],\n       [0.85831622, 0.6       , 0.35714286],\n       [0.11293634, 0.7       , 0.28571429],\n       [0.        , 0.7       , 0.71428571],\n       [0.73100616, 0.725     , 0.21428571],\n       [0.19712526, 0.3       , 0.71428571],\n       [0.4312115 , 0.375     , 0.71428571],\n       [0.89322382, 0.325     , 0.28571429],\n       [0.59958932, 0.575     , 0.        ],\n       [0.84599589, 0.65      , 0.        ],\n       [0.70020534, 0.3       , 0.07142857],\n       [0.30800821, 0.35      , 0.21428571],\n       [0.89117043, 0.35      , 0.85714286],\n       [0.20533881, 0.85      , 0.        ],\n       [0.93429158, 0.45      , 0.42857143],\n       [0.02669405, 0.675     , 0.07142857],\n       [0.71868583, 0.975     , 0.28571429],\n       [0.50513347, 0.15      , 0.42857143],\n       [0.86652977, 0.6       , 1.        ],\n       [0.04312115, 0.125     , 0.78571429],\n       [0.57905544, 0.425     , 0.28571429],\n       [0.15195072, 0.975     , 0.21428571],\n       [0.58521561, 0.875     , 1.        ],\n       [0.20328542, 0.925     , 0.21428571],\n       [0.51950719, 0.2       , 0.85714286],\n       [0.0698152 , 0.575     , 0.42857143],\n       [0.44558522, 0.15      , 0.57142857],\n       [0.24435318, 0.075     , 0.21428571],\n       [0.40862423, 0.95      , 0.        ],\n       [0.58932238, 0.775     , 0.78571429],\n       [0.4476386 , 0.175     , 0.35714286],\n       [0.23613963, 0.425     , 0.21428571],\n       [0.75359343, 0.175     , 0.42857143],\n       [0.04106776, 0.475     , 0.71428571],\n       [0.63039014, 0.625     , 0.42857143],\n       [0.44147844, 0.9       , 0.71428571],\n       [0.62217659, 0.075     , 0.07142857],\n       [0.9486653 , 0.6       , 0.14285714],\n       [0.36960986, 0.825     , 0.71428571],\n       [0.19917864, 0.125     , 0.64285714],\n       [0.15400411, 1.        , 0.57142857],\n       [0.88295688, 0.875     , 0.78571429],\n       [0.37577002, 0.625     , 0.42857143],\n       [0.90554415, 0.175     , 0.42857143],\n       [0.82956879, 0.35      , 0.21428571],\n       [0.97946612, 0.775     , 0.        ],\n       [0.63655031, 0.125     , 0.21428571]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 83
    },
    {
      "cell_type": "code",
      "source": "scaler.transform([[200 , 4.5 , 30]])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 84,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.38603696, 0.875     , 0.35714286]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 84
    },
    {
      "cell_type": "markdown",
      "source": "### You are working on a project to build a model to predict stock prices. The dataset contains many  features, such as company financial data and market trends. Explain how you would use PCA to reduce the  dimensionality of the dataset\n\n\n\nUsing Principal Component Analysis (PCA) to reduce the dimensionality of a dataset for predicting stock prices is a great approach. Here's how you can do it step-by-step:\n\n#### **Step-by-Step Process**\n\n**Standardize the Data:**\nBefore applying PCA, it's important to standardize the data so that each feature has a mean of 0 and a standard deviation of 1. This ensures that each feature contributes equally to the analysis.\n\n**Apply PCA:**\nUse PCA to transform the standardized data into a new set of features (principal components) that capture the most variance in the data.\n\n**Select the Number of Principal Components:**\nChoose the number of principal components that explain a significant amount of the variance in the data. This can be done by examining the explained variance ratio.\n\n**Transform the Data:**\nTransform the original data into the reduced set of principal components.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data=np.array([1,5,10,15,20]).reshape(-1,1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": "data",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 88,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 1],\n       [ 5],\n       [10],\n       [15],\n       [20]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 88
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\n\nscaler=MinMaxScaler(feature_range=(-1,1))\nscaled_data=scaler.fit_transform(data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 90
    },
    {
      "cell_type": "code",
      "source": "scaled_data",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 91,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[-1.        ],\n       [-0.57894737],\n       [-0.05263158],\n       [ 0.47368421],\n       [ 1.        ]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 91
    },
    {
      "cell_type": "code",
      "source": "scaled_data.flatten()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 92,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([-1.        , -0.57894737, -0.05263158,  0.47368421,  1.        ])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 92
    },
    {
      "cell_type": "markdown",
      "source": "### For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data = {\n    'height': [170, 160, 180, 175, 165],\n    'weight': [70, 60, 80, 75, 65],\n    'age': [25, 30, 35, 40, 45],\n    'gender': ['male', 'female', 'male', 'female', 'male'],\n    'blood_pressure': [120, 110, 130, 125, 115]\n}\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 97
    },
    {
      "cell_type": "code",
      "source": "data=pd.DataFrame(data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 98
    },
    {
      "cell_type": "code",
      "source": "data",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 99,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   height  weight  age  gender  blood_pressure\n0     170      70   25    male             120\n1     160      60   30  female             110\n2     180      80   35    male             130\n3     175      75   40  female             125\n4     165      65   45    male             115",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>height</th>\n      <th>weight</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>blood_pressure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>170</td>\n      <td>70</td>\n      <td>25</td>\n      <td>male</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160</td>\n      <td>60</td>\n      <td>30</td>\n      <td>female</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>180</td>\n      <td>80</td>\n      <td>35</td>\n      <td>male</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>175</td>\n      <td>75</td>\n      <td>40</td>\n      <td>female</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165</td>\n      <td>65</td>\n      <td>45</td>\n      <td>male</td>\n      <td>115</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 99
    },
    {
      "cell_type": "code",
      "source": "def encode_gender(gender):\n    if gender==\"male\":\n        return 1\n    else:\n        return 0",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 100
    },
    {
      "cell_type": "code",
      "source": "data['gender']=data['gender'].apply(encode_gender)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 103
    },
    {
      "cell_type": "code",
      "source": "data",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 104,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   height  weight  age  gender  blood_pressure\n0     170      70   25       1             120\n1     160      60   30       0             110\n2     180      80   35       1             130\n3     175      75   40       0             125\n4     165      65   45       1             115",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>height</th>\n      <th>weight</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>blood_pressure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>170</td>\n      <td>70</td>\n      <td>25</td>\n      <td>1</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>160</td>\n      <td>60</td>\n      <td>30</td>\n      <td>0</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>180</td>\n      <td>80</td>\n      <td>35</td>\n      <td>1</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>175</td>\n      <td>75</td>\n      <td>40</td>\n      <td>0</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>165</td>\n      <td>65</td>\n      <td>45</td>\n      <td>1</td>\n      <td>115</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 104
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\nscaler.fit_transform(data[['height' , 'weight' , 'age' , 'blood_pressure']])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 106,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 0.        ,  0.        , -1.41421356,  0.        ],\n       [-1.41421356, -1.41421356, -0.70710678, -1.41421356],\n       [ 1.41421356,  1.41421356,  0.        ,  1.41421356],\n       [ 0.70710678,  0.70710678,  0.70710678,  0.70710678],\n       [-0.70710678, -0.70710678,  1.41421356, -0.70710678]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 106
    },
    {
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\n\npipeline = Pipeline(steps=[\n    ('pca', pca)\n])\n\npipeline.fit(data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 108,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Pipeline(steps=[('pca', PCA(n_components=2))])",
            "text/html": "<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=2))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=2))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=2)</pre></div> </div></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 108
    },
    {
      "cell_type": "code",
      "source": "explained_variance = pca.explained_variance_ratio_\nprint(explained_variance)\nprint(len(explained_variance))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0.75291771 0.24598477]\n2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 111
    },
    {
      "cell_type": "code",
      "source": "cumulative_variance = explained_variance.cumsum()\ncumulative_variance",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 110,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0.75291771, 0.99890248])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 110
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}