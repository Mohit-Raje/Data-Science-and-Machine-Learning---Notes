{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c86048d-c0f7-4f22-8fe7-b8cfdb3e0ee9",
   "metadata": {},
   "source": [
    "## Q1. What is Gradient Boosting Regression?\n",
    "\"Gradient Boosting Regression is an ensemble technique that builds a strong regressor by sequentially adding weak models, usually decision trees, where each new model tries to minimize the residual errors of the combined previous models.\"\n",
    "\n",
    "üî∂ 2. Core Idea (Go Deep Here):\n",
    "‚ÄúAt each step, the algorithm doesn‚Äôt just fit on the raw data ‚Äî it fits on the gradient of the loss function. That is, it learns in the direction where the loss (like Mean Squared Error) is decreasing the most.‚Äù\n",
    "\n",
    "‚úÖ Why it's called \"Gradient\":\n",
    "The residuals (errors) are the negative gradients of the loss function.\n",
    "\n",
    "So, we‚Äôre using gradient descent in function space ‚Äî each model is a step toward minimizing the loss.\n",
    "\n",
    "So instead of just minimizing error by brute force, Gradient Boosting minimizes it by following the gradient of the loss function, which tells us how to improve predictions in the steepest descent direction. That‚Äôs the core ‚Äî combining weak learners using gradient optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343d0c2-2f20-44c1-a980-4cd29d2d5fc9",
   "metadata": {},
   "source": [
    "## Q2. What is a weak learner in Gradient Boosting? \n",
    "\n",
    "A weak learner is a model that performs just slightly better than random guessing on the given task.\n",
    "\n",
    "In Gradient Boosting, the most commonly used weak learner is a shallow decision tree, often called a decision stump (a tree with 1‚Äì3 splits).\n",
    "\n",
    "\n",
    " Example:\n",
    "Suppose you have a regression task.\n",
    "\n",
    "The first tree predicts the average (say ‚Çπ50L), but there's a sample with true value ‚Çπ55L.\n",
    "\n",
    "The next tree (weak learner) learns to predict a part of this 5L error ‚Äî say 1L.\n",
    "\n",
    "Over time, combining many such weak predictions gets you very close to the actual target.\n",
    "\n",
    "üîÑ Summary:\n",
    "‚úÖ Weak learner = simple model (e.g., shallow tree)\n",
    "\n",
    "‚úÖ Used to learn from residuals or gradients\n",
    "\n",
    "‚úÖ When added together = strong learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9f86c-151c-4a75-9be0-968ed7587327",
   "metadata": {},
   "source": [
    "## Q3. What is the intuition behind the Gradient Boosting algorithm?\n",
    "\n",
    "The intution behind gradient boosting is to use bossting technique along with gradient optimaization. In this technque the weak learners are fitted on the raw data but are fitted on the gradient of the loss function , so that the the next weak learner comes to know the direction and magnitude of the error and gradient descent happens to reach the global minima . \n",
    "Everey next learner in the sequence tries to fitted on the gradiet of the previous model so that those errors/residual can be reduced , when such weak leanrners are combined the resultant is a stable , robust model whose output can be trusted .\n",
    "\n",
    "Gradient Boosting is about fitting weak learners not on data directly, but on the gradients of a loss function ‚Äî guiding each model to reduce the error in the most efficient direction.\"\n",
    "\n",
    "Gradient Boosting combines the idea of boosting ‚Äî where models are built sequentially to correct errors of previous ones ‚Äî with gradient descent optimization.\n",
    "\n",
    "Instead of training weak learners on the raw target values, we train each learner on the negative gradient of the loss function, which represents the direction and magnitude of the error.\n",
    "\n",
    "This tells the next model how to adjust the prediction to reduce the error most effectively.\n",
    "\n",
    "Each subsequent learner corrects the mistakes of the combined ensemble so far. Over many iterations, the model gradually improves and converges toward a strong, stable predictor that minimizes the overall loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a59d1-684d-4b86-97e8-e31d4f7a7b95",
   "metadata": {},
   "source": [
    "## Q4. How does Gradient Boosting algorithm build an ensemble of weak learners?\n",
    "Core Idea:\n",
    "Gradient Boosting builds an ensemble sequentially, where each new weak learner (usually a decision tree) is trained to correct the errors (residuals or gradients) made by the current model.\n",
    "\n",
    "üîÅ Step-by-Step Intuition:\n",
    "Start with a base model:\n",
    "Typically, we initialize with a constant prediction (like the mean of the target values for regression).\n",
    "\n",
    "Compute the loss (error):\n",
    "For each data point, calculate the difference between the predicted and actual values ‚Äî this is the residual.\n",
    "\n",
    "Fit a weak learner to the residuals:\n",
    "Train a shallow decision tree to predict these residuals (or, more precisely, the negative gradient of the loss function).\n",
    "\n",
    "Update the model:\n",
    "Add the new learner's predictions to the overall model with a learning rate \n",
    "ùúÇ\n",
    "Œ∑:\n",
    "\n",
    "ùêπ\n",
    "ùëö\n",
    "(\n",
    "ùë•\n",
    ")\n",
    "=\n",
    "ùêπ\n",
    "ùëö\n",
    "‚àí\n",
    "1\n",
    "(\n",
    "ùë•\n",
    ")\n",
    "+\n",
    "ùúÇ\n",
    "‚ãÖ\n",
    "‚Ñé\n",
    "ùëö\n",
    "(\n",
    "ùë•\n",
    ")\n",
    "F \n",
    "m\n",
    "‚Äã\n",
    " (x)=F \n",
    "m‚àí1\n",
    "‚Äã\n",
    " (x)+Œ∑‚ãÖh \n",
    "m\n",
    "‚Äã\n",
    " (x)\n",
    "Repeat:\n",
    "Continue this process for a fixed number of iterations or until the error stops improving.\n",
    "\n",
    "üì¶ Example:\n",
    "Let's say you are predicting house prices.\n",
    "\n",
    "The first model predicts ‚Çπ50L for every house (mean value).\n",
    "\n",
    "You calculate errors: one house‚Äôs true price is ‚Çπ55L ‚Üí residual = ‚Çπ5L.\n",
    "\n",
    "The next tree learns to predict this ‚Çπ5L gap.\n",
    "\n",
    "Add a fraction of it (say 10%): new prediction = ‚Çπ50L + 0.1 √ó ‚Çπ5L = ‚Çπ50.5L.\n",
    "\n",
    "This continues for all data points and for many rounds.\n",
    "\n",
    "üîë Key Points to Say in an Interview:\n",
    "\"Each weak learner is trained to minimize the gradient of the loss function.\"\n",
    "\n",
    "\"The ensemble is built stage-by-stage, and each stage improves upon the last.\"\n",
    "\n",
    "\"Eventually, the model converges to a strong predictor by minimizing the overall loss.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa132d6f-5889-497e-8c92-f29957d57c98",
   "metadata": {},
   "source": [
    "## Q5. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?\n",
    "\n",
    "1. Build a base model - Usually gives mean value as output\n",
    "2. Calculate the gradient of the loss function i.e the error with direction\n",
    "3. Fit the next model with with this gradient of loss function , i.e the next model (DTR) in sequence will not predict the actual avle but the gradient / error . This helps to next learner to reduce the error using gradient optimization process.\n",
    "    To Get back the result i.e the value not the error :\n",
    "        Value = base model prediction + Alpha*(predicted error)\n",
    "        \n",
    "4. Repeat the process until the error is minimized and desired accuracy is achieved\n",
    "\n",
    "Gradient Boosting fits each new weak learner on the gradient of the loss function, updating predictions gradually to minimize overall error using gradient descent in function space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b84c41-2783-4072-8882-fb43ab5fd8f9",
   "metadata": {},
   "source": [
    "## Q6. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth tooptimise the performance of the model. Use grid search or random search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da2171c-0aa2-4771-b0e6-f03c66f66a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2acb61e-3058-4cd2-85e9-d587b8e1d24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X , y = make_regression(n_samples=1000 , n_features=4 ,n_informative=3 , random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441fc48b-dfed-480a-a083-174a08b75988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.33 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52df4773-ccf3-4434-97b3-0dcbef3d2694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "GBR=GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99cfbc97-f259-4d66-995e-cdaa6e53d615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],     # How fast the model learns (lower = more robust)\n",
    "    'n_estimators': [100, 200, 300, 500],        # Number of boosting rounds (trees)\n",
    "    'max_depth': [3, 5, 7, 10]                   # Depth of each tree (controls model complexity)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b1b7ae-6bd7-4d80-88a7-bc597cfe6311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gscv=GridSearchCV(GBR , param_grid=param_grid , refit=True , cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb0403d-836e-49ed-bbd9-c8bd2e40dc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7, 10],\n",
       "                         'n_estimators': [100, 200, 300, 500]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e8999e-532b-4bb6-9c46-1a38b3045925",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525de026-e38e-473f-bbe3-1c29fe2626d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991503589129462"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31cdbbd9-a69d-4f35-b26c-e37bd9bb4b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=GradientBoostingRegressor(learning_rate=0.1 , max_depth=3, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5326ec9-40c3-4130-b15e-d498b30d252c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=500)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4889223-11d9-4142-ace2-5463d7fc4ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b76546fb-54cf-4934-bd1c-bbbded7f38a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score , mean_absolute_error , mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ac12a-3a48-4a7c-bb1d-c8d84ce69a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test , y_pred))\n",
    "print(mean_absolute_error(y_test , y_pred))\n",
    "print(mean_squared_error(y_test  , y_pred))\n",
    "print(np.sqrt())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
