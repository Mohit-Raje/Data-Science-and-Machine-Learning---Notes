{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "281e167d-efaa-4e98-bca4-6d4fcd4dad51",
   "metadata": {},
   "source": [
    "## Q1. What is a projection and how is it used in PCA?\n",
    "A projection refers to the process of mapping high-dimensional data onto a lower-dimensional subspace.\n",
    "In PCA, data is projected onto new axes called principal components, which are directions in which the data varies the most. The first few components capture the most important patterns while reducing the number of dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3b9ac-e08f-4eb6-abb2-8fe75193a87d",
   "metadata": {},
   "source": [
    "## Q2. How does the optimization problem in PCA work, and what is it trying to achieve?\n",
    "PCA solves an optimization problem where it:\n",
    "\n",
    "Maximizes the variance captured by each principal component.\n",
    "\n",
    "Or equivalently, minimizes the reconstruction error when projecting the data onto a lower-dimensional subspace.\n",
    "\n",
    "Technically, PCA finds the eigenvectors (principal components) of the covariance matrix of the data and sorts them by their corresponding eigenvalues (variance explained)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e891d5-f8d0-4816-bb84-e86318bf3d05",
   "metadata": {},
   "source": [
    "## Q3. What is the relationship between covariance matrices and PCA?\n",
    "The covariance matrix shows how features in the data vary together.\n",
    "\n",
    "PCA computes the covariance matrix of the standardized data.\n",
    "\n",
    "Then, it performs eigen decomposition to find the directions (principal components) where variance is maximized.\n",
    "\n",
    "The eigenvectors of this matrix are the principal components, and the eigenvalues represent the variance along each component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85479d1-fce9-486c-9e88-1edf4be81ade",
   "metadata": {},
   "source": [
    "## Q4 How does the choice of number of principal components impact the performance of PCA?\n",
    "\n",
    "Choosing too few components may cause loss of important information, leading to underfitting.\n",
    "\n",
    "Choosing too many components may retain noise and increase computation, with less benefit.\n",
    "\n",
    "Ideally, you choose components that capture around 90–95% of the variance, using tools like the explained variance plot or cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64771395-e6f1-414f-9a15-67aa80788c95",
   "metadata": {},
   "source": [
    "## Q5 . What are some common applications of PCA in data science and machine learning?\n",
    "Data visualization (e.g., reducing data to 2D or 3D for plotting)\n",
    "\n",
    "Noise reduction\n",
    "\n",
    "Preprocessing before clustering or classification\n",
    "\n",
    "Image compression\n",
    "\n",
    "Gene expression analysis in bioinformatics\n",
    "\n",
    "Recommendation systems\n",
    "\n",
    "Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898ec8b-2ba4-4fc4-a096-7aa9a09b8836",
   "metadata": {},
   "source": [
    "## Q6. What is the relationship between spread and variance in PCA?\n",
    "\n",
    "In PCA:\n",
    "\n",
    "Spread of the data refers to how scattered the data points are.\n",
    "\n",
    "Variance is a numerical measure of this spread.\n",
    "\n",
    "PCA identifies the directions in which the spread (variance) of the data is largest and uses those directions (principal components) for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082802f-7292-4833-a2b0-c8f412cc5cfd",
   "metadata": {},
   "source": [
    "## Q7. How does PCA use the spread and variance of the data to identify principal components?\n",
    "\n",
    "PCA:\n",
    "\n",
    "Standardizes the data (zero mean, unit variance).\n",
    "\n",
    "Computes the covariance matrix to find how features vary together.\n",
    "\n",
    "Performs eigen decomposition on this matrix.\n",
    "\n",
    "Selects the directions (eigenvectors) with the highest eigenvalues — these directions have the highest variance (spread) in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f2a91-9b9c-4b93-aee2-6a5ed48371f2",
   "metadata": {},
   "source": [
    "## Q8. How does PCA handle data with high variance in some dimensions but low variance in others?\n",
    "PCA prioritizes dimensions with higher variance:\n",
    "\n",
    "The components aligned with high-variance dimensions are selected first.\n",
    "\n",
    "Low-variance dimensions are often ignored or contribute less to the principal components.\n",
    "\n",
    "This way, PCA naturally filters out less informative features and reduces noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109812ec-7ac8-4202-9409-90c27e354506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
